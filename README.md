**Computer Vision Labs Portfolio**

**Overview**

This portfolio showcases my expertise in computer vision through various hands-on labs implementing state-of-the-art deep learning techniques. The projects explore different self-supervised learning methods, transformer-based architectures, and advanced feature extraction techniques. Below is an overview of the key concepts covered, along with references to well-known papers or authors that have contributed to these fields.

Labs and Mastered Techniques:

**1. Masked Autoencoders (MAE)**

Mastery:

Learned how to train Masked Autoencoders (MAE) for self-supervised learning.

Understood the role of masked image modeling (MIM) in learning visual representations.

Explored the use of transformers for feature extraction in an unsupervised manner.

Reference:

Kaiming He et al., "Masked Autoencoders Are Scalable Vision Learners," NeurIPS 2021. [Paper]

**2. Vision Transformers (ViT)**


Mastery:

Implemented Vision Transformers (ViTs) for image classification tasks.

Compared the performance of ViTs with convolutional networks.

Understood how self-attention mechanisms enhance feature learning.

Reference:

Alexey Dosovitskiy et al., "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale," ICLR 2021. [Paper]

**3. Variational Autoencoders (VAE)**



Mastery:

Developed a Variational Autoencoder (VAE) for generative modeling.

Learned how VAEs model the latent space for efficient data generation.

Understood KL-divergence regularization in latent variable models.

Reference:

Kingma, Diederik P., and Max Welling. "Auto-Encoding Variational Bayes." ICLR 2014. [Paper]

**4. Self-Supervised Learning (SSL) – Contrastive Learning**



Mastery:

Implemented contrastive learning methods like SimCLR.

Understood how instance discrimination helps in self-supervised feature learning.

Used augmentation strategies to improve representation learning.

Reference:

Ting Chen et al., "A Simple Framework for Contrastive Learning of Visual Representations (SimCLR)," ICML 2020. [Paper]

**5. Self-Supervised Learning (SSL) – Rotation Prediction**


Mastery:

Explored pretext tasks like rotation prediction for self-supervised learning.

Understood how networks can learn semantic representations without labels.

Implemented models trained to recognize rotated versions of images.

Reference:

Spyros Gidaris, Praveer Singh, Nikos Komodakis, "Unsupervised Representation Learning by Predicting Image Rotations," ICLR 2018. [Paper]


**Conclusion**

Through these labs, I have gained practical experience in self-supervised learning, transformer-based architectures, and generative modeling techniques. This portfolio serves as a demonstration of my ability to implement, analyze, and evaluate cutting-edge deep learning models in computer vision.


